{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  1\n",
      "0                           Wow... Loved this place.  1\n",
      "1                                 Crust is not good.  0\n",
      "2          Not tasty and the texture was just nasty.  0\n",
      "3  Stopped by during the late May bank holiday of...  1\n",
      "4  The selection on the menu was great and so wer...  1\n",
      "                                                   0  1\n",
      "0  So there is no way for me to plug it in here i...  0\n",
      "1                        Good case, Excellent value.  1\n",
      "2                             Great for the jawbone.  1\n",
      "3  Tied to charger for conversations lasting more...  0\n",
      "4                                  The mic is great.  1\n",
      "                                                   0  1\n",
      "0  A very, very, very slow-moving, aimless movie ...  0\n",
      "1  Not sure who was more lost - the flat characte...  0\n",
      "2  Attempting artiness with black & white and cle...  0\n",
      "3       Very little music or anything to speak of.    0\n",
      "4  The best scene in the movie was when Gerardo i...  1\n"
     ]
    }
   ],
   "source": [
    "yelp = pd.read_csv('sentiment labelled sentences/yelp_labelled.txt', sep=\"\t\", header=None)\n",
    "amazon = pd.read_csv('sentiment labelled sentences/amazon_cells_labelled.txt', sep=\"\t\", header=None)\n",
    "imdb = pd.read_csv('sentiment labelled sentences/imdb_labelled.txt', sep=\"\t\", header=None)\n",
    "print yelp.head()\n",
    "print amazon.head()\n",
    "print imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of labels:\n",
      "Yelp\n",
      "Label 0:  500\n",
      "Label 1:  500\n",
      "Amazon\n",
      "Label 0:  500\n",
      "Label 1:  500\n",
      "IMdB\n",
      "Label 0:  362\n",
      "Label 1:  386\n"
     ]
    }
   ],
   "source": [
    "print \"Count of labels:\"\n",
    "print \"Yelp\"\n",
    "print \"Label 0: \", np.count_nonzero(yelp[1][:] == 0)\n",
    "print \"Label 1: \", np.count_nonzero(yelp[1][:] == 1)\n",
    "print \"Amazon\"\n",
    "print \"Label 0: \", np.count_nonzero(amazon[1][:] == 0)\n",
    "print \"Label 1: \", np.count_nonzero(amazon[1][:] == 1)\n",
    "print \"IMdB\"\n",
    "print \"Label 0: \", np.count_nonzero(imdb[1][:] == 0)\n",
    "print \"Label 1: \", np.count_nonzero(imdb[1][:] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "print stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sindhu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
    "table = string.maketrans(\"\",\"\")\n",
    "\n",
    "for each in [yelp, amazon, imdb]:\n",
    "    for j in range(0, len(each)):\n",
    "        without_punc = str.lower(each[0][j]).translate(table, string.punctuation)\n",
    "        each[0][j] = pattern.sub('', without_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service prompt\n"
     ]
    }
   ],
   "source": [
    "print yelp[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_train = np.asarray(yelp[:800])\n",
    "yelp_test = np.asarray(yelp[801:])\n",
    "amazon_train = np.asarray(amazon[:800])\n",
    "amazon_test = np.asarray(amazon[801:])\n",
    "imdb_train = np.asarray(imdb[:600])\n",
    "imdb_test = np.asarray(imdb[601:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['average' 'avocado' 'avoid' ..., 'yum' 'yummy' 'zero']\n"
     ]
    }
   ],
   "source": [
    "set_yelp = []\n",
    "for each in yelp_train[:,0]:\n",
    "    set_yelp.append(each.split())\n",
    "set_yelp = np.unique(np.hstack(set_yelp))\n",
    "print set_yelp[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['applifies' 'appointments' 'area' ..., 'youd' 'youll' 'zero']\n"
     ]
    }
   ],
   "source": [
    "set_amz = []\n",
    "for each in amazon_train[:,0]:\n",
    "    set_amz.append(each.split())\n",
    "set_amz = np.unique(np.hstack(set_amz))\n",
    "print set_amz[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['always' 'amateurish' 'amaze' ..., 'zombiez' '\\xc2\\x85script' '\\xc2\\x96']\n"
     ]
    }
   ],
   "source": [
    "set_imdb = []\n",
    "for each in imdb_train[:,0]:\n",
    "    set_imdb.append(each.split())\n",
    "set_imdb = np.unique(np.hstack(set_imdb))\n",
    "print set_imdb[100:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
